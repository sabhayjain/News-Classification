{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"News_Category_Dataset_v2.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.loc[df[\"category\"].isin([\"SPORTS\", \"TECH\", \"BUSINESS\", \"ENTERTAINMENT\", \"POLITICS\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/morgan-fr...</td>\n",
       "      <td>\"It is not right to equate horrific incidents ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "5  ENTERTAINMENT  Morgan Freeman 'Devastated' That Sexual Harass...   \n",
       "\n",
       "         authors                                               link  \\\n",
       "1  Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2     Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3     Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4     Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "5     Ron Dicker  https://www.huffingtonpost.com/entry/morgan-fr...   \n",
       "\n",
       "                                   short_description       date  \n",
       "1                           Of course it has a song. 2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26  \n",
       "5  \"It is not right to equate horrific incidents ... 2018-05-26  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df.headline + \" \" + df.short_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\?[\\]\\|@,;#+_].')\n",
    "BAD_SYMBOLS_RE = re.compile('[^a-z ]')\n",
    "def text_prepare(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE,' ', text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE,' ', text)\n",
    "    text = re.sub(r\"\\s+\" , \" \" , text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: text_prepare(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>will smith joins diplo and nicky jam for the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>hugh grant marries for the first time at age t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>jim carrey blasts castrato adam schiff and dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/morgan-fr...</td>\n",
       "      <td>\"It is not right to equate horrific incidents ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>morgan freeman devastated that sexual harassme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "5  ENTERTAINMENT  Morgan Freeman 'Devastated' That Sexual Harass...   \n",
       "\n",
       "         authors                                               link  \\\n",
       "1  Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2     Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3     Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4     Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "5     Ron Dicker  https://www.huffingtonpost.com/entry/morgan-fr...   \n",
       "\n",
       "                                   short_description       date  \\\n",
       "1                           Of course it has a song. 2018-05-26   \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26   \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26   \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26   \n",
       "5  \"It is not right to equate horrific incidents ... 2018-05-26   \n",
       "\n",
       "                                                Text  \n",
       "1  will smith joins diplo and nicky jam for the w...  \n",
       "2  hugh grant marries for the first time at age t...  \n",
       "3  jim carrey blasts castrato adam schiff and dem...  \n",
       "4  julianna margulies uses donald trump poop bags...  \n",
       "5  morgan freeman devastated that sexual harassme...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.Text)\n",
    "X = tokenizer.texts_to_sequences(df.Text)\n",
    "df['words'] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "      <th>Text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>will smith joins diplo and nicky jam for the w...</td>\n",
       "      <td>[35, 919, 1750, 10794, 7, 13335, 4591, 9, 1, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>hugh grant marries for the first time at age t...</td>\n",
       "      <td>[3271, 4236, 7195, 9, 1, 66, 63, 19, 655, 1, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>jim carrey blasts castrato adam schiff and dem...</td>\n",
       "      <td>[1346, 5082, 2266, 28014, 1412, 5564, 7, 139, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>[21754, 16204, 1628, 33, 11, 16205, 7725, 2, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/morgan-fr...</td>\n",
       "      <td>\"It is not right to equate horrific incidents ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>morgan freeman devastated that sexual harassme...</td>\n",
       "      <td>[2621, 6735, 5083, 13, 313, 781, 386, 78, 3007...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "5  ENTERTAINMENT  Morgan Freeman 'Devastated' That Sexual Harass...   \n",
       "\n",
       "         authors                                               link  \\\n",
       "1  Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2     Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3     Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4     Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "5     Ron Dicker  https://www.huffingtonpost.com/entry/morgan-fr...   \n",
       "\n",
       "                                   short_description       date  \\\n",
       "1                           Of course it has a song. 2018-05-26   \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26   \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26   \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26   \n",
       "5  \"It is not right to equate horrific incidents ... 2018-05-26   \n",
       "\n",
       "                                                Text  \\\n",
       "1  will smith joins diplo and nicky jam for the w...   \n",
       "2  hugh grant marries for the first time at age t...   \n",
       "3  jim carrey blasts castrato adam schiff and dem...   \n",
       "4  julianna margulies uses donald trump poop bags...   \n",
       "5  morgan freeman devastated that sexual harassme...   \n",
       "\n",
       "                                               words  \n",
       "1  [35, 919, 1750, 10794, 7, 13335, 4591, 9, 1, 9...  \n",
       "2  [3271, 4236, 7195, 9, 1, 66, 63, 19, 655, 1, 3...  \n",
       "3  [1346, 5082, 2266, 28014, 1412, 5564, 7, 139, ...  \n",
       "4  [21754, 16204, 1628, 33, 11, 16205, 7725, 2, 6...  \n",
       "5  [2621, 6735, 5083, 13, 313, 781, 386, 78, 3007...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "X = list(sequence.pad_sequences(df.words, maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61700"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total categories: 5\n",
      "category\n",
      "BUSINESS          5937\n",
      "ENTERTAINMENT    16058\n",
      "POLITICS         32739\n",
      "SPORTS            4884\n",
      "TECH              2082\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat = df.groupby('category')\n",
    "print(\"total categories:\", cat.ngroups)\n",
    "print(cat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61700"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.groupby('category').size().index.tolist()\n",
    "category_int = {}\n",
    "int_category = {}\n",
    "for i, k in enumerate(categories):\n",
    "    category_int.update({k:i})\n",
    "    int_category.update({i:k})\n",
    "\n",
    "df['id'] = df['category'].apply(lambda x: category_int[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "      <th>Text</th>\n",
       "      <th>words</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>will smith joins diplo and nicky jam for the w...</td>\n",
       "      <td>[35, 919, 1750, 10794, 7, 13335, 4591, 9, 1, 9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>hugh grant marries for the first time at age t...</td>\n",
       "      <td>[3271, 4236, 7195, 9, 1, 66, 63, 19, 655, 1, 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>jim carrey blasts castrato adam schiff and dem...</td>\n",
       "      <td>[1346, 5082, 2266, 28014, 1412, 5564, 7, 139, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>[21754, 16204, 1628, 33, 11, 16205, 7725, 2, 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/morgan-fr...</td>\n",
       "      <td>\"It is not right to equate horrific incidents ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>morgan freeman devastated that sexual harassme...</td>\n",
       "      <td>[2621, 6735, 5083, 13, 313, 781, 386, 78, 3007...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "5  ENTERTAINMENT  Morgan Freeman 'Devastated' That Sexual Harass...   \n",
       "\n",
       "         authors                                               link  \\\n",
       "1  Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2     Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3     Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4     Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "5     Ron Dicker  https://www.huffingtonpost.com/entry/morgan-fr...   \n",
       "\n",
       "                                   short_description       date  \\\n",
       "1                           Of course it has a song. 2018-05-26   \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26   \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26   \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26   \n",
       "5  \"It is not right to equate horrific incidents ... 2018-05-26   \n",
       "\n",
       "                                                Text  \\\n",
       "1  will smith joins diplo and nicky jam for the w...   \n",
       "2  hugh grant marries for the first time at age t...   \n",
       "3  jim carrey blasts castrato adam schiff and dem...   \n",
       "4  julianna margulies uses donald trump poop bags...   \n",
       "5  morgan freeman devastated that sexual harassme...   \n",
       "\n",
       "                                               words  id  \n",
       "1  [35, 919, 1750, 10794, 7, 13335, 4591, 9, 1, 9...   1  \n",
       "2  [3271, 4236, 7195, 9, 1, 66, 63, 19, 655, 1, 3...   1  \n",
       "3  [1346, 5082, 2266, 28014, 1412, 5564, 7, 139, ...   1  \n",
       "4  [21754, 16204, 1628, 33, 11, 16205, 7725, 2, 6...   1  \n",
       "5  [2621, 6735, 5083, 13, 313, 781, 386, 78, 3007...   1  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np_utils.to_categorical(list(df.id))\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43673 unique tokens.\n",
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0335   ,  0.1923   ,  0.75185  ,  0.052949 , -0.13     ,\n",
       "        0.32704  ,  0.13995  ,  1.029    , -1.2252   , -0.56681  ,\n",
       "       -0.08998  ,  0.087026 ,  0.12782  , -0.39067  ,  0.46194  ,\n",
       "       -0.52275  ,  0.043902 , -0.25056  ,  0.46998  ,  0.59955  ,\n",
       "        0.22225  ,  0.6047   ,  0.74104  ,  1.013    ,  0.4105   ,\n",
       "        1.0875   , -0.77584  , -0.14632  ,  0.24677  , -0.50827  ,\n",
       "       -0.38744  , -0.79767  ,  0.095715 ,  0.49008  , -0.77654  ,\n",
       "       -0.28072  ,  0.26816  , -0.56382  ,  0.30244  ,  0.80363  ,\n",
       "       -1.0137   , -0.1754   , -0.12751  , -0.29914  ,  0.91612  ,\n",
       "       -0.26122  , -0.16641  , -0.09657  ,  0.69747  , -1.387    ,\n",
       "       -0.1499   , -0.069914 ,  0.54274  ,  0.57055  ,  0.56829  ,\n",
       "       -1.8202   , -0.331    ,  0.82934  ,  1.2996   ,  0.67671  ,\n",
       "       -0.26366  ,  1.0841   , -0.55754  ,  0.39118  ,  0.0038266,\n",
       "        0.20567  ,  0.23146  , -0.8063   ,  0.36182  , -1.3672   ,\n",
       "       -0.45553  , -0.30046  ,  0.65406  ,  0.17487  ,  0.6837   ,\n",
       "        0.60704  ,  0.5714   , -0.246    ,  0.36948  ,  1.1949   ,\n",
       "        0.66063  , -0.65138  , -1.3167   ,  0.046118 , -0.93002  ,\n",
       "        0.16485  , -0.25135  ,  0.043969 ,  0.1626   ,  1.0498   ,\n",
       "        0.78027  , -0.72591  , -0.75555  ,  0.25469  , -0.35116  ,\n",
       "        0.27495  , -0.31867  ,  0.77627  ,  0.12477  , -0.076081 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"rain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = layers.Embedding(len(word_index)+1,\n",
    "                            EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = layers.Input(shape=(100,))\n",
    "x = embedding_layer(input1)\n",
    "x = layers.Bidirectional(layers.LSTM(32, dropout = 0.2, return_state = True, return_sequences = True))(x)\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = layers.Bidirectional(layers.LSTM(32, dropout = 0.2, return_state = True, return_sequences = True))(x)\n",
    "state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
    "state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
    "\n",
    "context_vector, attention_weights = Attention(64)(lstm, state_h)\n",
    "\n",
    "x = layers.Dense(32, activation = \"relu\")(context_vector)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(16, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(5, activation = \"softmax\")(x)\n",
    "model = tf.keras.Model(inputs = input1, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     4367400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) [(None, 100, 64), (N 34048       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) [(None, 100, 64), (N 24832       bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_4[0][1]            \n",
      "                                                                 bidirectional_4[0][2]            \n",
      "                                                                 bidirectional_4[0][3]            \n",
      "                                                                 bidirectional_4[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64)           0           bidirectional_5[0][1]            \n",
      "                                                                 bidirectional_5[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         ((None, 64), (None,  8385        bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           2080        attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 5)            85          dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,437,358\n",
      "Trainable params: 69,958\n",
      "Non-trainable params: 4,367,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55530 samples, validate on 6170 samples\n",
      "Epoch 1/40\n",
      "55530/55530 [==============================] - 252s 5ms/sample - loss: 0.8430 - acc: 0.7164 - val_loss: 0.5064 - val_acc: 0.8457\n",
      "Epoch 2/40\n",
      "55530/55530 [==============================] - 243s 4ms/sample - loss: 0.6108 - acc: 0.8002 - val_loss: 0.4472 - val_acc: 0.8562\n",
      "Epoch 3/40\n",
      "55530/55530 [==============================] - 241s 4ms/sample - loss: 0.5663 - acc: 0.8150 - val_loss: 0.4083 - val_acc: 0.8619\n",
      "Epoch 4/40\n",
      "55530/55530 [==============================] - 239s 4ms/sample - loss: 0.5403 - acc: 0.8198 - val_loss: 0.3954 - val_acc: 0.8634\n",
      "Epoch 5/40\n",
      "55530/55530 [==============================] - 239s 4ms/sample - loss: 0.5117 - acc: 0.8284 - val_loss: 0.3733 - val_acc: 0.8695\n",
      "Epoch 6/40\n",
      "55530/55530 [==============================] - 240s 4ms/sample - loss: 0.4967 - acc: 0.8350 - val_loss: 0.3718 - val_acc: 0.8804\n",
      "Epoch 7/40\n",
      "55530/55530 [==============================] - 239s 4ms/sample - loss: 0.4777 - acc: 0.8407 - val_loss: 0.3542 - val_acc: 0.8846\n",
      "Epoch 8/40\n",
      "55530/55530 [==============================] - 239s 4ms/sample - loss: 0.4724 - acc: 0.8438 - val_loss: 0.3430 - val_acc: 0.8853\n",
      "Epoch 9/40\n",
      "55530/55530 [==============================] - 237s 4ms/sample - loss: 0.4577 - acc: 0.8475 - val_loss: 0.3405 - val_acc: 0.8890\n",
      "Epoch 10/40\n",
      "55530/55530 [==============================] - 238s 4ms/sample - loss: 0.4521 - acc: 0.8508 - val_loss: 0.3356 - val_acc: 0.8911\n",
      "Epoch 11/40\n",
      "55530/55530 [==============================] - 241s 4ms/sample - loss: 0.4361 - acc: 0.8554 - val_loss: 0.3481 - val_acc: 0.8891\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fad0a5f488>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, verbose=1,batch_size=64, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = np.argmax(model.predict(x_val),1)\n",
    "y_val_true = np.argmax(y_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [int_category[0], int_category[1], int_category[2], int_category[3], int_category[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.73      0.67      0.70       607\n",
      "ENTERTAINMENT       0.94      0.88      0.91      1627\n",
      "     POLITICS       0.90      0.96      0.93      3234\n",
      "       SPORTS       0.90      0.83      0.86       512\n",
      "         TECH       0.67      0.56      0.61       190\n",
      "\n",
      "     accuracy                           0.89      6170\n",
      "    macro avg       0.83      0.78      0.80      6170\n",
      " weighted avg       0.89      0.89      0.89      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_true, y_val_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
